{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDyBR_cxkTcv"
      },
      "source": [
        "## Introducción a PyTorch (Parte 1)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pglez82/DeepLearningWeb/blob/master/labs/notebooks/Introducci%C3%B3n%20a%20PyTorch%20(Parte%201).ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "PyTorch es un framework de aprendizaje profundo desarrollado por Facebook, de **código abierto** y con contribuciones de miles de usuarios. Es una alternativa a otros frameworks como TensorFlow o MXNet. El lenguaje de programación utilizado por este framework es Python (aunque muchas de sus partes están programas en otros lenguajes como C++). En este tutorial, vamos a aprender los fundamentos de PyTorch para que puedas utilizarlo en el resto de prácticas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLFEpCgikTcw"
      },
      "source": [
        "#### Primeros pasos\n",
        "Lo primero consiste en ver si tenemos PyTorch instalado y conocer su versión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVEhE3wokTcw",
        "outputId": "7442e816-e25e-4c50-d0e1-f1c7b9d10b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yosaUwTQkTcx"
      },
      "source": [
        "si en la salida anterior ves **cpu** será que estás ejecutando una compilación de PyTorch solo con soporte para CPU y no GPU. Si por el contrario quieres ejecutar PyTorch en una máquina con GPU como Google Colab (o incluso tu propia máquina con GPU y Cuda instalado), la salida de este comando debería indicartelo. Ten en cuenta que la versión con GPU también soporta entrenamientos en la CPU (lo contrario no es cierto)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juzLsBTukTcx"
      },
      "source": [
        "Un aspecto importante en los experimentos que hagamos será la reproducibilidad de resultados. Establecemos una semilla para que todos los números aleatorios generados sean los mismos ejecución tras ejecución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGV8OhBTkTcy",
        "outputId": "a65d3d57-a7e4-447f-e292-ce50196e0080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7da5f9d644b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.manual_seed(2032)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbSMR-rRkTcy"
      },
      "source": [
        "#### Tensores\n",
        "\n",
        "Los tensores son la pieza clave en cualquier framework de aprendizaje profundo. Son equivalentes a los arrays de Numpy pero tienen ciertas diferencias muy importantes:\n",
        "\n",
        "1. Los tensores **pueden moverse entre diferentes dispositivos**. Es decir, podemos tener un tensor en CPU y moverlo a la GPU y todos los cálculos realizados con este pasarán a realizarse en este dispositivo.\n",
        "2. Los tensores están preparados para diferenciar sobre ellos (calcular las derivadas parciales necesarias para aplicar descenso de gradiente).\n",
        "\n",
        "De todas maneras, una de las principales ventajas de PyTorch es que si sabemos operar con arrays de Numpy, cambiar a hacerlo con tensores será muy sencillo. Vamos a crear nuestro primer Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8b_a6UfkTcy",
        "outputId": "0e63ccc8-0281-4591-b2fe-212da6d5151f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.6528e-21, 4.5074e-41, 5.6528e-21, 4.5074e-41],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00,        nan, 1.8788e+31, 1.7220e+22]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(3, 4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f6ipIekkTcz"
      },
      "source": [
        "aquí tenemos un tensor de 3x4 de números reales, inicializado alteatoriamente. Podemos mostrar su dimensión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFh3b6KYkTcz",
        "outputId": "fad2e1b1-a4c9-47c6-81e5-028cf60f1dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hHUwNUakTcz"
      },
      "source": [
        "También es posible inicializar tensores con otros valores, como por ejemplo, ceros, unos o valores aleatorios entre 0 y 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "untkLPV1kTcz",
        "outputId": "32f84c4b-80d0-43f7-8cee-1a6fd4fa43bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[0.6282, 0.7710, 0.5404, 0.5480],\n",
            "        [0.0920, 0.3038, 0.9887, 0.5169],\n",
            "        [0.7733, 0.7820, 0.8844, 0.8440]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.zeros(3,4))\n",
        "print(torch.ones(3,4))\n",
        "print(torch.rand(3,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bA2WDHSkTcz"
      },
      "source": [
        "Otra manera de crear un tensor es hacerlo desde un array de numpy existente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7umgISNkTc0",
        "outputId": "be6c1d77-aef4-4fab-9e08-d00c562e3e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuDROyyAkTc0"
      },
      "source": [
        "En este case se pude ver que como el array era de números enteros, el tensor resultante mantiene este tipo. Siempre podemos ver el **tipo de los elementos de un tensor** con la siguiente instrucción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuyqWxW9kTc0",
        "outputId": "ac13f4ec-1aa1-4375-c202-5177e04b87c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "print(tensor.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDzT1clikTc0"
      },
      "source": [
        "Ten en cuenta que **el tipo es crítico** ya que nuestra red va a requerir muchísimos parámetros que al final van a ser tensores y la memoria de nuestros dispositivos es limitada. Te recomiendo el siguiente [enlace](https://pytorch.org/docs/stable/tensors.html) para conocer los diferentes tipos y saber cuando ocupa cada uno en memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssq9rET5kTc0"
      },
      "source": [
        "Además de crear tensores, muchas veces es interesante convertirlos de vuelta a Numpy. Podemos hacerlo de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfpTwMXekTc0",
        "outputId": "1a9d50c3-defe-4f8b-fac6-c807c38f59c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tensor.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMIgT2PkkTc0"
      },
      "source": [
        "Ten en cuenta que la llamada cpu() lo que hace es mover el tensor a la cpu (si no está ya). Es importante hacer esta llamada porque para pasar el tensor a numpy tiene que estar en cpu primero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBnBlzgWkTc0"
      },
      "source": [
        "Para mover tensores de un dispositivo a otro podemos hacerlo de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SsS_BRmkkTc0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tensor = tensor.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qyrRKvykTc1"
      },
      "source": [
        "obviamente para que esto funcione debemos tener PyTorch instalado con soporte para cuda (sino el tensor se quedará en la cpu). En este caso **cuda:0** indica que queremos mover el tensor a la primera GPU del sistema. Es importante tener en cuenta que `tensor.to` devuelve el tensor en el nuevo dispositivo por tanto debemos recordar guardarlo en una variable para posteriormente poder usarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZMkDjSakTc1"
      },
      "source": [
        "#### Operaciones con tensores\n",
        "\n",
        "Existen multitud de operaciones que se pueden realizar con tensores. En el siguiente [enlace](https://pytorch.org/docs/stable/tensors.html#) tienes una descripción completa de todas las operaciones que se pueden realizar. Aquí vamos a describir las más básicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_D1_xT0kTc1",
        "outputId": "1cad6d41-86b9-4b61-82ab-f475486e8e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6985, 0.2108],\n",
            "        [0.1112, 0.1474],\n",
            "        [0.8116, 0.1859]])\n",
            "tensor([[0.5345, 0.4596],\n",
            "        [0.3705, 0.5302],\n",
            "        [0.5715, 0.7342]])\n",
            "tensor([[1.2330, 0.6704],\n",
            "        [0.4817, 0.6776],\n",
            "        [1.3831, 0.9201]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.rand(3,2)\n",
        "t2 = torch.rand(3,2)\n",
        "suma = t1+t2\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(suma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSlt9xj7kTc1"
      },
      "source": [
        "ten en cuenta que esta operación crea un nuevo tensor en memoria. En PyTorch es posible también realizar **operaciones sobre los mismos tensores**, para no gastar espacio extra en memoria. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EADuvJCJkTc1",
        "outputId": "f9f9f380-ada0-4edf-9d3c-6ed09f2e2a91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2330, 0.6704],\n",
              "        [0.4817, 0.6776],\n",
              "        [1.3831, 0.9201]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "t2.add_(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulem-tdTkTc1"
      },
      "source": [
        "Tenemos otras operaciones disponibles pero en general, **las operaciones básicas que puedes hacer con Numpy también se pueden hacer con tensores**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI5EsNI-kTc1",
        "outputId": "c0685300-daef-4f12-ee5d-98d5a45b9558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4333, 0.4734],\n",
            "        [0.1678, 0.0093],\n",
            "        [0.9842, 0.3493]])\n",
            "tensor([[0.5617, 0.6045],\n",
            "        [0.8110, 0.5253],\n",
            "        [0.3047, 0.6035]])\n",
            "Resta:\n",
            "tensor([[-0.1284, -0.1311],\n",
            "        [-0.6432, -0.5160],\n",
            "        [ 0.6795, -0.2542]])\n",
            "Multiplicación por un escalar:\n",
            "tensor([[1.2999, 1.4201],\n",
            "        [0.5034, 0.0278],\n",
            "        [2.9526, 1.0479]])\n",
            "Multiplicación de matrices elemento a elemento:\n",
            "tensor([[0.2434, 0.2861],\n",
            "        [0.1361, 0.0049],\n",
            "        [0.2999, 0.2108]])\n",
            "Multiplicación de matrices normal:\n",
            "tensor([[0.5295, 0.6001, 0.4177],\n",
            "        [0.0999, 0.1410, 0.0567],\n",
            "        [0.7640, 0.9817, 0.5107]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.rand(3,2)\n",
        "t2 = torch.rand(3,2)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(\"Resta:\")\n",
        "print(t1-t2)\n",
        "print(\"Multiplicación por un escalar:\")\n",
        "print(t1*3)\n",
        "print(\"Multiplicación de matrices elemento a elemento:\")\n",
        "print(t1*t2)\n",
        "print(\"Multiplicación de matrices normal:\")\n",
        "#Importante: estamos haciendo la transpuesta de t2 para poder multiplicarlas y que coincidan las dimesiones\n",
        "print(t1@t2.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8mvFuYkTc1"
      },
      "source": [
        "#### Cambio de la forma de un tensor\n",
        "\n",
        "En muchas ocasiones necesitamos cambiar la forma de un tensor, para luego poder operar con él correctamente. Para esto es muy adecuada la función **view**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eirfeVIxkTc1",
        "outputId": "bb59e705-82a3-4463-d8a7-071ac37c0f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n"
          ]
        }
      ],
      "source": [
        "#arange crea un tensor con valores desde 0 hasta n-1\n",
        "t1 = torch.arange(10)\n",
        "print(t1)\n",
        "\n",
        "#digamos que queremos una matriz de 5x2\n",
        "print(t1.view(5,2))\n",
        "\n",
        "#También podemos inferir dimensiones\n",
        "print(t1.view(5,-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzcSrdfnkTc1"
      },
      "source": [
        "es interesante entender que view devuelve un nuevo tensor pero que comparte la estructura interna con el tensor original, es decir, no estamos almacenando los datos de nuevo, sino simplemente **dándoles otra forma**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXrbbktYkTc1"
      },
      "source": [
        "#### Indexado\n",
        "El indexado funciona de igual manera que en Numpy. Veamos algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQh1kljfkTc2",
        "outputId": "f78b3474-7ef2-4854-c488-6393c8531723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "Solo la segunda fila (empieza a contar en cero):\n",
            "tensor([4, 5, 6, 7])\n",
            "Solo la última columna:\n",
            "tensor([ 3,  7, 11])\n",
            "Seleccionar el primer elemento de las dos primeras filas:\n",
            "tensor([0, 4])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.arange(12).view(3,4)\n",
        "print(t1)\n",
        "\n",
        "print(\"Solo la segunda fila (empieza a contar en cero):\")\n",
        "print(t1[1,:])\n",
        "print(\"Solo la última columna:\")\n",
        "print(t1[:,-1])\n",
        "print(\"Seleccionar el primer elemento de las dos primeras filas:\")\n",
        "print(t1[:2,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zmhVmzNkTc2"
      },
      "source": [
        "### Ejercicios propuestos\n",
        "1. Navega por la documentación de PyTorch (https://pytorch.org/docs/stable/torch.html) y busca un par de funciones interesantes para operar con tensores que no aparezcan en este notebook.\n",
        "2. Ejecuta el notebook en Google Colab. Cambia el tipo de dispositivo de tu máquina y trata de ejecutar el código anterior en diferentes dispositivos. Usa el atributo del tensor `device` para conocer en que dispositivo se encuentra.\n",
        "3. Intenta realizar una operación con dos tensores que se encuentren en dispositivos diferentes. ¿Qué sucede en este caso?\n",
        "4. Ejecuta el notebook en local, comprueba que todos los tensores están en la CPU.\n",
        "5. Implementa un perceptrón utilizando tensores en PyTorch. Comprueba que su salida ante una entrada concreta es correcta.\n",
        "6. Realiza las siguientes operaciones con tensores:\n",
        "   - Crear Tensores: Crea los siguientes tensores en PyTorch:\n",
        "      - Un tensor *t_1* de 10 elementos igualmente espaciados entre 0 y 1.\n",
        "      - Un tensor *t_2* de tamaño 3x3 con valores aleatorios.\n",
        "      - Un tensor *t_3* de tamaño 2x3x4 con todos sus elementos inicializados a 1.\n",
        "   - Extrae la segunda fila del tensor *t_2*.\n",
        "   - Cambia la forma (reshape) de *t_3* a un tensor 2D de tamaño 6x4.\n",
        "   - Transpón el tensor *t_2* (intercambia filas por columnas).\n",
        "   - Suma el tensor [1.0, 1.0, 1.0] a la primera fila de *t_2*.\n",
        "   - Realiza un producto elemento a elemento entre *t_2* y su transpuesta.\n",
        "   - Realiza un producto matricial entre *t_2* y su transpuesta.\n",
        "   - Selecciona todos los elementos de la *t_2* que sean mayores que 0.5.\n",
        "   - Crea un tensor booleano de la misma forma que el *t_2*, que sea True si el elemento es mayor que 0.5, y False en caso contrario.\n",
        "   - Cuenta cuantos elementos de *t_2* son mayores de que la media de los elementos de *t_2*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio Propuesto 1:\n",
        "\n",
        "Comando is_tensor -> Devuelve true si el objeto al que aplicamos la función es un tensor.\n",
        "\n",
        "Comando linspace -> Crea un tensor de una dimensión cuyos valores están igualmente espaciados en un rango dado."
      ],
      "metadata": {
        "id": "U5IGgOIkpti9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio Propuesto 3:\n",
        "\n"
      ],
      "metadata": {
        "id": "ugy_FeZDrY0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_cpu = torch.rand(3,4)\n",
        "tensor_gpu = torch.rand(3,4)\n",
        "\n",
        "tensor_cpu = tensor.to(\"cpu\")\n",
        "tensor_gpu = tensor.to(\"cuda:0\")\n",
        "\n",
        "#tensor_gpu.add_(tensor_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "aCC3Q7Sjsh_B",
        "outputId": "153fb11b-7c66-45e9-9fc6-6520c74bfa06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-220607836.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensor_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtensor_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vemos, si ejecutamos la suma en 2 dispositivos diferentes nos da error."
      ],
      "metadata": {
        "id": "nMExDzVEsxIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio Propuesto 5: (Demasiado movida)"
      ],
      "metadata": {
        "id": "p4yANNTXvugY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos los datos de entrada X y las etiquetas y:\n",
        "X =  torch.rand(5,2)\n",
        "y = torch.tensor([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0]\n",
        "])"
      ],
      "metadata": {
        "id": "LiZCRe_yv1Pe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos el sesgo y la varianza:\n"
      ],
      "metadata": {
        "id": "qAuk73ocxDUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio Propuesto 6:"
      ],
      "metadata": {
        "id": "U0ETF3ZgxocZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Un tensor t_1 de 10 elementos igualmente espaciados entre 0 y 1.\n",
        "t_1 = torch.linspace(0,1,10)\n",
        "print(t_1)\n",
        "\n",
        "#Un tensor t_2 de tamaño 3x3 con valores aleatorios\n",
        "t_2 = torch.rand(3,3)\n",
        "print(t_2)\n",
        "\n",
        "#Un tensor t_3 de tamaño 2x3x4 con todos sus elementos inicializados a 1.\n",
        "t_3 = torch.ones(2,3,4)\n",
        "print(t_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3zRNG10xv8w",
        "outputId": "82825274-7215-4aa0-ab56-95bf4fba4883"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000])\n",
            "tensor([[0.8616, 0.6108, 0.5161],\n",
            "        [0.7833, 0.0530, 0.8470],\n",
            "        [0.0586, 0.0789, 0.9867]])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extrae la segunda fila del tensor t_2.\n",
        "print(t_2[1,:])\n",
        "\n",
        "#Cambia la forma (reshape) de t_3 a un tensor 2D de tamaño 6x4.\n",
        "print(t_3.view(6,4))\n",
        "\n",
        "#Transpón el tensor t_2 (intercambia filas por columnas).\n",
        "t_2 = t_2.t()\n",
        "\n",
        "#Suma el tensor [1.0, 1.0, 1.0] a la primera fila de t_2.\n",
        "t_2[0,:].add_(torch.tensor([1.0, 1.0, 1.0]))\n",
        "\n",
        "#Realiza un producto elemento a elemento entre t_2 y su transpuesta.\n",
        "print(t_2*t_2.t())\n",
        "\n",
        "#Realiza un producto matricial entre t_2 y su transpuesta.\n",
        "print(t_2@t_2.t())\n",
        "\n",
        "#Selecciona todos los elementos de la t_2 que sean mayores que 0.5.\n",
        "print(t_2>0.5)\n",
        "\n",
        "#Crea un tensor booleano de la misma forma que el t_2, que sea True si el elemento es mayor que 0.5, y False en caso contrario.\n",
        "t_2bool = torch.empty(3,3)\n",
        "for i in range(t_2.size(0)):\n",
        "  for j in range(t_2.size(1)):\n",
        "    if t_2[i,j] > 0.5:\n",
        "      t_2bool[i,j] = True\n",
        "    else:\n",
        "      t_2bool[i,j] = False\n",
        "print(t_2bool)\n",
        "\n",
        "#Cuenta cuantos elementos de t_2 son mayores de que la media de los elementos de t_2.\n",
        "indices = torch.argwhere(t_2>t_2.mean())\n",
        "print(indices.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0msDmoyfp2",
        "outputId": "74adc6f8-710c-46e3-8556-a20456e7d6e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.7833, 0.0530, 0.8470])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[9.7251e+01, 2.6665e+01, 2.2845e+01],\n",
            "        [2.6665e+01, 2.8110e-03, 6.6811e-02],\n",
            "        [2.2845e+01, 6.6811e-02, 9.7350e-01]])\n",
            "tensor([[156.2861,  46.1751,  54.4252],\n",
            "        [ 46.1751,  21.2682,  20.9454],\n",
            "        [ 54.4252,  20.9454,  22.0860]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True, False, False],\n",
            "        [ True,  True,  True]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [1., 1., 1.]])\n",
            "5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}